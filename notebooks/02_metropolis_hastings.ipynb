{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Metropolis-Hastings algorithm\n",
    "Cleverly sampling probablity distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdKqAsOSJPz2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Metropolis-Hastings algorithm is a way to sample from a probability distribution in is widely used in probabilistic programming. `pymc` uses a variation of this when you run `pm.sample()`. The Metropolis-Hastings algorithm is an example of Markov Chain Monte Carlo (MCMC) methods.\n",
    " \n",
    "The Markov Chain part means that the next sample only depends on last one; you dont need to know anything about the history, just what your last step was. This might seem extreme, but let's compare it to using GPS to navigate. You can imagine that in order for you to find the way towards a goal, you really dont care about your history, you just need to know where you are right now. \n",
    "\n",
    "The Monte Carlo part means that we use random techniques to approximate the answer, instead of analytical methods.\n",
    "\n",
    "In this notebook, you will learn a few concepts:\n",
    "\n",
    "- trace plot\n",
    "- random walk\n",
    "- compare probabilities between distributions\n",
    "- Monte Carlo Markov Chains\n",
    "\n",
    "The goal is to get a bit more background on the MCMC method. The building blocks are random walks and calculating probabilities to make the random walk a bit less random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX9mG_l7Rzfe"
   },
   "source": [
    "## 1. Trace plot\n",
    "Let's draw a thousand samples from a normal distribution with $\\mu=0$ and $\\sigma=1$. We do this over time, and track what we have drawn. This is called a *trace plot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2vlNhDNZwRib",
    "outputId": "dd0b32f7-1589-4006-e917-3f8616c7695f"
   },
   "outputs": [],
   "source": [
    "\n",
    "t = np.linspace(0, 10, 1000)\n",
    "obs = []\n",
    "for step in t:\n",
    "    draw = stats.norm(loc=0, scale=1).rvs(size=1)\n",
    "    obs.append(draw)\n",
    "    plt.plot(\n",
    "        step,\n",
    "        draw,\n",
    "        \"b.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tt8EhNWFSlC_"
   },
   "source": [
    "As you can see, this is a normal distribution, but sideways. The x-axis is time, and the y-axis is the value we have drawn. The trace plot is a way to visualize the random walk.\n",
    "\n",
    "We could also plot all the observations without the time dimension in a histogram, and we will recognize the familiar normal distribution from which we have been sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "PtqIBCLuSMnr",
    "outputId": "0acca475-dbc0-473c-a851-3df808ad2288"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(obs), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6-Kmsr5S2fV"
   },
   "source": [
    "## 2. Random walk\n",
    "\n",
    "Now, we are going to do something else.\n",
    "We will draw from a distibution, but the distribution we are going to draw from is connected to the previous one.\n",
    "\n",
    "This is called a *random walk*. So: we start with $\\mu=0$, $\\sigma=1$. We draw a sample, let's say we draw 0.74. This will be the mean of the next draw, so: $\\mu=0.74$, $\\sigma=1$. Now we might draw 0.41. So, our next draw will be from a distribution with $\\mu=0.41$, $\\sigma=1$.\n",
    "\n",
    "You could compare this to the following: instead of doing the same thing over and over again, you will vary just a little bit, but usually you stay close to your previous behaviour. So you explore, but usually you don't take big jumps (to be precise: the standard deviation of your jump is 1).\n",
    "\n",
    "If we make a traceplot of this, we will see a line that drifts, one way or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "D0Zq8JsIxKFd",
    "outputId": "47e3d6a2-01c1-43c7-e114-fcb9d79dd86e"
   },
   "outputs": [],
   "source": [
    "# random walk\n",
    "t = np.linspace(0, 10, 1000)\n",
    "draw = 0\n",
    "obs = []\n",
    "for step in t:\n",
    "    draw = stats.norm(loc=draw, scale=1).rvs(size=1)\n",
    "    obs.append(draw)\n",
    "    plt.plot(\n",
    "        step,\n",
    "        draw,\n",
    "        \"b.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77OSRNrKT5Db"
   },
   "source": [
    "This result can't be mapped to a normal distribution easily! This is because the distribution we are sampling from is drifting over time, and this data is actually generated by many different distributions. It is like someone that is randomly changing his mind about where to go.\n",
    "\n",
    "## 3. compare probabilities\n",
    "### 3.1 Generate data\n",
    "Before we can start comparing, we need some data.\n",
    "Let's start with generating some big population of 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXzE7PF2KIfK"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "population = stats.norm(loc=20, scale=10).rvs(size=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1dffZICUScx"
   },
   "source": [
    "And from this population, we will sample a small observation of 100. We know what the underlying distribution is, but the data has become a bit more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlMLU1sHKPSh"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "observation = np.random.choice(population, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "kOzwYMxjK5EC",
    "outputId": "62489e0c-6482-4e2a-d8c2-a281f65f824e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.kdeplot(population, bw_adjust=0.2, color=\"black\", label=\"population\")\n",
    "sns.histplot(observation, stat=\"density\", bins=30, alpha=0.5, label=\"observation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9ZH4JKeUqqd"
   },
   "source": [
    "Now, let's imagine we have access to the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrOrmurPMH-r",
    "outputId": "74b68c9a-68f5-4c89-e17b-ad86c8894e92"
   },
   "outputs": [],
   "source": [
    "mu_obs = observation.mean()\n",
    "mu_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkReYGS6UwIF"
   },
   "source": [
    "But we want to estimate the standard deviation. Obviously, in this case, we could simply calculate the std as well (and we know that the std was actually 10 because we generated the data ourselves).\n",
    "\n",
    "But this is just an example created to be as simple as possible to show how this process works, where the advantage is that if at some point we do get more complex examples where it is not straight forward to calculate a value, we can still use inference. \n",
    "\n",
    "In addition to that, our inference will give an estimate about how close we are\n",
    "to the \"real\" std. For comparison, let's just directly calculate it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPxxtc21MZeB",
    "outputId": "31f30ddd-b977-47b1-f03a-fd8c38d8a82a"
   },
   "outputs": [],
   "source": [
    "observation.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try how close we can get to this value with MCMC sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCDZyp_OVcSM"
   },
   "source": [
    "### 3.2 Calculate the probability of the direction\n",
    "The metropolis-hastings algoritm makes a random walk, but it needs to determine how likely a new configuration is. This can serve as a type of gps or compas: it will tell us if we are going in the right direction.\n",
    "\n",
    "We can calculate that with the pdf function. How likely is it to draw a 0 from a distribution with parameters $\\mu=0$ and $\\sigma=1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BarpXbZwMfgU",
    "outputId": "2f639232-6f38-493d-fb3d-4003dd36c979"
   },
   "outputs": [],
   "source": [
    "stats.norm.pdf(0, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCivXDQcVtmB"
   },
   "source": [
    "The density of the probability for a normal distribution with $\\mu=0$ and\n",
    "$\\sigma=1$ to draw a 0 is about 0.4. \n",
    "\n",
    "Note: this is NOT a percentage!  for a continuous distribution, you can not give the probability\n",
    "of a point, only of a range. E.g. the probability of the outside temperature\n",
    "being 17.4 degrees is zero. You could only talk about the probability of the\n",
    "temperature to be between an interval, e.g. between 17.0 and 18.0, or maybe\n",
    "between 17.3 and 17.5. However, we can take the limit of an interval, which\n",
    "gives us the density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZYH5Z2VM3IP",
    "outputId": "6f28d1e5-462d-4873-8e66-bf3cb221c654"
   },
   "outputs": [],
   "source": [
    "stats.norm.pdf(2, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DnlTTe9WAf1"
   },
   "source": [
    "A value of 2 is much less likely. This means we can use the pdf to compare two draws, and to figure out if a draw is more, or less, likey to come from a specific distribution. Let's draw the pdf for a range of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "8RPpDAE8NBl1",
    "outputId": "fa49f99a-682a-4a42-d301-c34133786931"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 50)\n",
    "pdf = stats.norm.pdf(x, loc=0, scale=1)\n",
    "plt.scatter(x, pdf)\n",
    "plt.title(\"Samples from the pdf of the normal distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ-b0thXWHyL"
   },
   "source": [
    "This show us we can calculate the probabilities for a bunch of data, simultaneously. If we use a nicely spread range of datapoints, we get the familiar bell-shaped curve.\n",
    "\n",
    "However, we can also calculate the probability for every item from our observed\n",
    "data, under the assumption that the items are drawn from a normal distribution\n",
    "with a given mean and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuhO2R_bOcA8",
    "outputId": "0d6c618d-43b0-43e4-afc8-d8fedb4f5845"
   },
   "outputs": [],
   "source": [
    "probs = stats.norm(loc=mu_obs, scale=1).pdf(observation)\n",
    "probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are all the probabilities for all the observations we generated, assuming that the distribution we were sampling from was a normal distribution with $\\mu=\\texttt{mu\\_obs}$ and $\\sigma=1$.\n",
    "\n",
    "The nice thing is we can compare this to other assumed means and standard deviations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGL8cyTjWjhS"
   },
   "source": [
    "\n",
    "We could multiply all the probabilities together, but because multiplying a lot of small number will give us rounding errors we are often better off by taking the log and summing the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72tUrWC6y_Q4",
    "outputId": "4ccc3027-9d16-4566-f2f4-5049c34b612e"
   },
   "outputs": [],
   "source": [
    "np.sum(np.log(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Picking the most likely distribution\n",
    "Lets compare our observations with two different distributions, each with their own mean and standard deviation. We will use $\\mu=0$ and $\\sigma=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs1 = stats.norm(loc=mu_obs, scale=1).pdf(observation)\n",
    "probs2 = stats.norm(loc=mu_obs, scale=2).pdf(observation)\n",
    "np.sum(np.log(probs1)) < np.sum(np.log(probs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, std 2 is more likely! (which we know to be true, because we generated the data ourselves with std 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GoXrSbxXEwm"
   },
   "source": [
    "Because we will be comparing distributions, we don't need to translate the logs back with\n",
    "`np.exp` (we could do it, but it does not change the order, so for comparison it doesnt matter and we don't want to waste\n",
    "compute on something that doesnt matter). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gigNS0-XUuc"
   },
   "source": [
    "This is a metric that allows to compare different distributions. Let's take two normal distributions with the same mean but one has a $\\sigma=3$, the other $\\sigma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mu_WYymlzbDH",
    "outputId": "3ab6b66e-26a6-4c73-f276-d0360947319b"
   },
   "outputs": [],
   "source": [
    "from inference import Metropolis, Dist\n",
    "\n",
    "metropolis = Metropolis()\n",
    "dist_a = Dist(mu_obs, scale=3)\n",
    "dist_b = Dist(mu_obs, scale=1)\n",
    "a = metropolis.get_log_probs(observation, dist=dist_a)\n",
    "b = metropolis.get_log_probs(observation, dist=dist_b)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYbwRsJNXdmw"
   },
   "source": [
    "So, we can see, there is a much higher probability that our observations are\n",
    "coming from a distribution a with $\\sigma=3$ than from a distribution b with\n",
    "$\\sigma=1$.\n",
    "\n",
    "To keep things neat, we used a dataclass for our distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHBtwl6fXtaa"
   },
   "source": [
    "## 3.4 Accepting or rejecting proposals\n",
    "And now, let's make two different distributions, the first one starting with $\\mu=0$ and $\\sigma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iISGZWwRPgq-"
   },
   "outputs": [],
   "source": [
    "d1 = Dist(0, 1)\n",
    "\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Tahh5icX0kF"
   },
   "source": [
    "We will make a random walk, but we take just 1 step. We start with `d1` and we will use that standard deviation for a random walk.\n",
    "\n",
    "Because we want our new standard deviation to be positive, we need to pick a distribution that is always positive. We could pick many things for this (a half-cauchy, inverse-gamma, half-normal or exponential distribution). My implementation in `Metropolis.random_walk` assume that $\\sigma$ comes from an exponential distribution, but you could change that to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSsHKh1GUfCT",
    "outputId": "5de85a73-a820-4147-a856-199e2636b24d"
   },
   "outputs": [],
   "source": [
    "d2 = metropolis.random_walk(d1)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAgZTb8QZEMW"
   },
   "source": [
    "So, we did a first random walk with the two distributions, and after that we have the old distribution `d1`, and the new proposal distribution `d2` that has a different `scale` (i.e. standar deviation), but the same mean, produced by the random walk. Let's make a traceplot of this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "7WttC6Kr9czW",
    "outputId": "558cc037-f68a-4745-87e2-08f287e3b725"
   },
   "outputs": [],
   "source": [
    "d1 = Dist(0, 1)\n",
    "draw = 0\n",
    "for step in range(20):\n",
    "    print(d1.scale)\n",
    "    s = stats.expon.rvs(loc=d1.scale)\n",
    "    d1 = Dist(d1.loc, scale=s)\n",
    "    plt.plot(\n",
    "        step,\n",
    "        d1.scale,\n",
    "        \"b.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGwGeDWHZkpf"
   },
   "source": [
    "This is just a random walk that explores the space of probabilities by wandering around. But some wandering brings us to places that are more likely to succeed than others.\n",
    "Let's say we have a current distribution with $\\sigma=8$, and we would wander into two different directions. One brings us a $\\sigma=7.5$, the other $\\sigma=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks5088001-CA"
   },
   "outputs": [],
   "source": [
    "current = metropolis.get_log_probs(observation, dist=Dist(mu_obs, 8))\n",
    "proposed1 = metropolis.get_log_probs(observation, dist=Dist(mu_obs, 7.5))\n",
    "proposed2 = metropolis.get_log_probs(observation, dist=Dist(mu_obs, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCHZv7KHZ9vX"
   },
   "source": [
    "Now, what would be the more likely direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkZvNzTd2FyW",
    "outputId": "3f6fbd8a-79df-4850-818f-5f0e7af5bddd"
   },
   "outputs": [],
   "source": [
    "current, proposed1, proposed2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XJGiRa5aB--"
   },
   "source": [
    "`proposed1` is a bit less likely as our current distribution, `proposed2` is more likely.\n",
    "\n",
    "Metropolis-hastings handles this situation like this:\n",
    "\n",
    "- if the proposed distribution is more likely, always pick it.\n",
    "- if the proposed distribtuion is less likely, pick it with a chance proportional to how much more unlikely it is.\n",
    "\n",
    "To do this, we need to recalculate the actual probability (remember we have been working with *logprobs* so far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KqP5MH8ajN7",
    "outputId": "9bc654ef-4c6e-4c07-9b30-e97fa4ec0123"
   },
   "outputs": [],
   "source": [
    "np.exp(proposed1 - current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4E2XTaCas90"
   },
   "source": [
    "If the difference is 0.5, we will pick the new distribution 50% of the time, even though it is worse. In this case, the chance is about 1 in 100. Lets see how that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUvyILPd3jm-",
    "outputId": "1014bfa5-0261-4b26-908a-48b91ca415ae"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "np.mean([metropolis.accept(proposed1, current) for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2YhncNb4PI"
   },
   "source": [
    "So, yes, indeed the new distribtion is accepted only 1% of the time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYQCU0aE3lp6",
    "outputId": "af9e4a59-5f5e-4ad6-c901-79c55b6ebc4b"
   },
   "outputs": [],
   "source": [
    "np.mean([metropolis.accept(proposed2, current) for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQzISwatcAC0"
   },
   "source": [
    "...while the more likely proposed2 is always accepted.\n",
    "\n",
    "# 4 Putting it all together\n",
    "\n",
    "We can now wrap this all together:\n",
    "\n",
    "1. We start with a distribution, and a new one.\n",
    "2. We make a random walk, based on what we have.\n",
    "3. We calculate how likely our new distribution is, given the data\n",
    "4. If the new distribution is more likely, we accept it. If not, we accept\n",
    "   proportional.\n",
    "\n",
    "Look it up in the source code src.models.inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY2Du8UpdL9r"
   },
   "source": [
    "Let's test this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7VkU8v-6glp",
    "outputId": "1b42aef2-530f-4d13-aef0-86d1ac84d1d2"
   },
   "outputs": [],
   "source": [
    "trace = metropolis(n=1000, observation=observation, mu_obs=mu_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Gogn-HsbA26Q",
    "outputId": "27da8c7e-f890-43f8-8b83-0687d32b0fcc"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(trace, columns=[\"sigma\", \"accept\"]).reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=data, x=\"index\", y=\"sigma\", hue=\"accept\")\n",
    "plt.ylim(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnUWgrCgd_0G"
   },
   "source": [
    "What do we see? The process takes a few steps to random walk the intial distribution with $\\sigma=1$ to the more likely area around $sigma=10$.\n",
    "\n",
    "This is called the *burn-in* period. After we are around that value, we will accept other values occasionaly, but the wandering converges around a value of 10 because everything that is too far away from that will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUTS\n",
    "After exploring the Metropolis-Hastings algorithm in detail, it's worth contrasting it with the No-U-Turn Sampler (NUTS) that's commonly used in PyMC. While Metropolis-Hastings proposes new states using a fixed proposal distribution and accepts or rejects them based on the target distribution, NUTS adaptively tunes the trajectory length by detecting when the sampler starts to double back on itself (making a \"U-turn\"). This adaptive behavior allows NUTS to efficiently explore both local and global features of the posterior distribution without requiring manual tuning of parameters. NUTS typically converges faster than Metropolis-Hastings for complex models with many parameters, which explains its popularity as the default sampler in modern probabilistic programming frameworks like PyMC."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "metropolis-hastings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
